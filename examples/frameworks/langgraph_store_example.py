"""
LangGraph + Gaugid Store Example

This example demonstrates how to use GaugidStore as a BaseStore for LangGraph,
allowing agents to use Gaugid profiles as persistent key-value stores.

Requires: OPENAI_API_KEY and GAUGID_CONNECTION_TOKEN environment variables
Install: pip install gaugid[langgraph]
"""

import asyncio
import os
from typing import TypedDict, Annotated, Sequence
from operator import add

try:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
    from langgraph.graph import StateGraph, START, END
    from gaugid.integrations.langgraph import GaugidStore
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    print("âš ï¸  LangGraph not installed. Install with: pip install gaugid[langgraph]")


class ChatState(TypedDict):
    """State for the chatbot graph."""
    messages: Annotated[Sequence[BaseMessage], add]
    user_context: str


async def main():
    """Main function demonstrating LangGraph + Gaugid Store integration."""
    
    if not LANGGRAPH_AVAILABLE:
        print("âŒ LangGraph is not installed.")
        print("   Install with: pip install gaugid[langgraph]")
        return
    
    # Check for API keys
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("âŒ Error: OPENAI_API_KEY environment variable not set")
        return
    
    connection_token = os.getenv("GAUGID_CONNECTION_TOKEN")
    if not connection_token:
        print("âŒ Error: GAUGID_CONNECTION_TOKEN environment variable not set")
        return
    
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("     ğŸš€ LangGraph + Gaugid Store")
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    try:
        # Create Gaugid store
        print("1ï¸âƒ£ Creating GaugidStore for LangGraph...")
        store = GaugidStore(
            connection_token=connection_token,
            namespace_prefix=("langgraph", "chatbot"),
            memory_type="episodic",
        )
        print("   âœ… GaugidStore created\n")
        
        # Create LLM
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=openai_api_key)
        
        # Define chatbot node
        def chatbot_node(state: ChatState) -> dict:
            """Main chatbot node that generates responses."""
            system_prompt = f"""You are a helpful AI assistant.

USER CONTEXT (from their Gaugid profile):
{state['user_context']}

Adapt your responses based on the user's preferences and context."""
            
            messages = [SystemMessage(content=system_prompt)] + list(state["messages"])
            response = llm.invoke(messages)
            
            return {"messages": [response]}
        
        # Build graph
        print("2ï¸âƒ£ Creating LangGraph with GaugidStore...")
        graph = StateGraph(ChatState)
        graph.add_node("chatbot", chatbot_node)
        graph.add_edge(START, "chatbot")
        graph.add_edge("chatbot", END)
        
        # Compile with GaugidStore as checkpointer
        app = graph.compile(checkpointer=store)
        print("   âœ… Graph compiled with GaugidStore\n")
        
        # Example conversation
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print("   ğŸ’¬ Example Conversation")
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
        
        config = {"configurable": {"thread_id": "example-thread-1"}}
        
        # Initial state with user context
        initial_state = {
            "messages": [HumanMessage(content="Hello! Tell me about yourself.")],
            "user_context": "User is interested in AI and machine learning.",
        }
        
        result = app.invoke(initial_state, config)
        print(f"User: {initial_state['messages'][0].content}")
        print(f"Assistant: {result['messages'][-1].content}\n")
        
        # Store some data in the store
        print("3ï¸âƒ£ Storing data in GaugidStore...")
        await store.aput(
            namespace=("langgraph", "chatbot", "preferences"),
            key="user_pref_1",
            value={"preference": "prefers technical explanations", "source": "conversation"},
        )
        print("   âœ… Data stored\n")
        
        # Retrieve data
        print("4ï¸âƒ£ Retrieving data from GaugidStore...")
        item = await store.aget(
            namespace=("langgraph", "chatbot", "preferences"),
            key="user_pref_1",
        )
        if item:
            print(f"   âœ… Retrieved: {item.value}\n")
        
        # Search data
        print("5ï¸âƒ£ Searching GaugidStore...")
        results = await store.asearch(
            namespace_prefix=("langgraph", "chatbot"),
            limit=5,
        )
        print(f"   âœ… Found {len(results)} items\n")
        
    finally:
        # Cleanup
        if 'store' in locals():
            await store.close()
    
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("                    âœ¨ Example Complete!")
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    print("ğŸ’¡ The store persists data in Gaugid profiles across sessions!")


if __name__ == "__main__":
    asyncio.run(main())
