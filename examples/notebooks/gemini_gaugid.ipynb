{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Google Gemini + Gaugid Integration\n",
        "\n",
        "This notebook demonstrates how to integrate Gaugid SDK with Google Gemini 3 to build a personalized chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import google.generativeai as genai\n",
        "from gaugid import GaugidClient\n",
        "\n",
        "# Set your API keys\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your-key-here\"\n",
        "os.environ[\"GAUGID_CONNECTION_TOKEN\"] = \"your-token-here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def load_user_context(client: GaugidClient, user_did: str) -> str:\n",
        "    \"\"\"Load user context from Gaugid profile.\"\"\"\n",
        "    profile = await client.get_profile(\n",
        "        user_did=user_did,\n",
        "        scopes=[\"a2p:preferences\", \"a2p:professional\", \"a2p:context\", \"a2p:interests\"]\n",
        "    )\n",
        "    \n",
        "    memories = profile.get(\"memories\", {}).get(\"episodic\", [])\n",
        "    context_parts = []\n",
        "    for memory in memories:\n",
        "        category = memory.get(\"category\", \"general\")\n",
        "        content = memory.get(\"content\", \"\")\n",
        "        context_parts.append(f\"- [{category}] {content}\")\n",
        "    \n",
        "    return \"\\n\".join(context_parts) if context_parts else \"No user context available.\"\n",
        "\n",
        "# Initialize clients\n",
        "gaugid_client = GaugidClient(connection_token=os.environ[\"GAUGID_CONNECTION_TOKEN\"])\n",
        "user_did = \"did:a2p:user:demo\"\n",
        "\n",
        "# Load user context\n",
        "user_context = await load_user_context(gaugid_client, user_did)\n",
        "print(\"User context loaded:\")\n",
        "print(user_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure Gemini with user context\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "system_instruction = f\"\"\"You are a helpful AI assistant.\n",
        "\n",
        "USER PROFILE (from Gaugid):\n",
        "{user_context}\n",
        "\n",
        "Adapt your responses to match user preferences and expertise level.\"\"\"\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-3-flash-exp\",\n",
        "    system_instruction=system_instruction\n",
        ")\n",
        "\n",
        "# Start chat\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "# Example conversation\n",
        "user_input = \"What are the best practices for async Python?\"\n",
        "response = chat.send_message(user_input)\n",
        "\n",
        "print(f\"User: {user_input}\")\n",
        "print(f\"\\nAssistant: {response.text}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
