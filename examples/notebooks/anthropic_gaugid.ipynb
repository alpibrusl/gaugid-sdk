{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Anthropic Claude + Gaugid Integration\n",
        "\n",
        "This notebook demonstrates how to integrate Gaugid SDK with Anthropic Claude 4.5 to build a personalized chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import asyncio\n",
        "from anthropic import Anthropic\n",
        "from anthropic.types import MessageParam\n",
        "from gaugid import GaugidClient\n",
        "\n",
        "# Set your API keys\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"your-key-here\"\n",
        "os.environ[\"GAUGID_CONNECTION_TOKEN\"] = \"your-token-here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def load_user_context(client: GaugidClient) -> str:\n",
        "    \"\"\"Load user context from Gaugid profile using connection token mode.\"\"\"\n",
        "    # Connection token mode: No DID needed - profile resolved from token\n",
        "    profile = await client.get_profile(\n",
        "        scopes=[\"a2p:preferences\", \"a2p:professional\", \"a2p:context\", \"a2p:interests\"]\n",
        "    )\n",
        "    \n",
        "    # Extract memories from different memory types\n",
        "    memories = profile.get(\"memories\", {})\n",
        "    episodic = memories.get(\"episodic\", [])\n",
        "    semantic = memories.get(\"semantic\", [])\n",
        "    procedural = memories.get(\"procedural\", [])\n",
        "    \n",
        "    context_parts = []\n",
        "    \n",
        "    # Add episodic memories\n",
        "    for memory in episodic:\n",
        "        category = memory.get(\"category\", \"general\")\n",
        "        content = memory.get(\"content\", \"\")\n",
        "        context_parts.append(f\"- [Episodic: {category}] {content}\")\n",
        "    \n",
        "    # Add semantic memories\n",
        "    for memory in semantic:\n",
        "        category = memory.get(\"category\", \"general\")\n",
        "        content = memory.get(\"content\", \"\")\n",
        "        context_parts.append(f\"- [Semantic: {category}] {content}\")\n",
        "    \n",
        "    # Add procedural memories\n",
        "    for memory in procedural:\n",
        "        category = memory.get(\"category\", \"general\")\n",
        "        content = memory.get(\"content\", \"\")\n",
        "        context_parts.append(f\"- [Procedural: {category}] {content}\")\n",
        "    \n",
        "    return \"\\n\".join(context_parts) if context_parts else \"No user context available.\"\n",
        "\n",
        "# Initialize clients\n",
        "anthropic_client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
        "gaugid_client = GaugidClient(connection_token=os.environ[\"GAUGID_CONNECTION_TOKEN\"])\n",
        "\n",
        "# Load user context (connection token mode - no DID needed)\n",
        "user_context = await load_user_context(gaugid_client)\n",
        "print(\"User context loaded:\")\n",
        "print(user_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chat with Claude\n",
        "messages: list[MessageParam] = []\n",
        "\n",
        "user_input = \"What are the best practices for async Python?\"\n",
        "\n",
        "messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "system_prompt = f\"\"\"You are a helpful AI assistant.\n",
        "\n",
        "USER PROFILE (from Gaugid):\n",
        "{user_context}\n",
        "\n",
        "Adapt your responses to match user preferences and expertise level.\"\"\"\n",
        "\n",
        "response = anthropic_client.messages.create(\n",
        "    model=\"claude-4-5\",\n",
        "    max_tokens=4096,\n",
        "    system=system_prompt,\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(f\"User: {user_input}\")\n",
        "print(f\"\\nAssistant: {response.content[0].text}\")\n",
        "\n",
        "# Optionally, save the conversation as a memory\n",
        "# Using connection token mode (no DID needed)\n",
        "memory_result = await gaugid_client.propose_memory(\n",
        "    content=f\"User asked about async Python best practices\",\n",
        "    category=\"a2p:professional\",\n",
        "    memory_type=\"episodic\",\n",
        "    confidence=0.9,\n",
        "    context=\"Conversation with Claude assistant\"\n",
        ")\n",
        "print(f\"\\nMemory saved: {memory_result.get('proposal_id')}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
