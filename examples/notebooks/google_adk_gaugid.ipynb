{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google ADK + Gaugid Integration\n",
    "\n",
    "This notebook demonstrates how to integrate Gaugid SDK with Google Agent Development Kit (ADK) to build production-ready multi-agent systems with personalized user context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import google.generativeai as genai\n",
    "from gaugid import GaugidClient\n",
    "\n",
    "# Set your API keys\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your-key-here\"\n",
    "os.environ[\"GAUGID_CONNECTION_TOKEN\"] = \"your-token-here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_user_context(client: GaugidClient) -> str:\n",
    "    \"\"\"Load user context from Gaugid profile using connection token mode.\"\"\"\n",
    "    # Connection token mode: No DID needed - profile resolved from token\n",
    "    profile = await client.get_profile(\n",
    "        scopes=[\"a2p:preferences\", \"a2p:professional\", \"a2p:context\", \"a2p:interests\"]\n",
    "    )\n",
    "    \n",
    "    # Extract memories from different memory types\n",
    "    memories = profile.get(\"memories\", {})\n",
    "    episodic = memories.get(\"episodic\", [])\n",
    "    semantic = memories.get(\"semantic\", [])\n",
    "    procedural = memories.get(\"procedural\", [])\n",
    "    \n",
    "    context_parts = []\n",
    "    \n",
    "    # Add episodic memories\n",
    "    for memory in episodic:\n",
    "        category = memory.get(\"category\", \"general\")\n",
    "        content = memory.get(\"content\", \"\")\n",
    "        context_parts.append(f\"- [Episodic: {category}] {content}\")\n",
    "    \n",
    "    # Add semantic memories\n",
    "    for memory in semantic:\n",
    "        category = memory.get(\"category\", \"general\")\n",
    "        content = memory.get(\"content\", \"\")\n",
    "        context_parts.append(f\"- [Semantic: {category}] {content}\")\n",
    "    \n",
    "    # Add procedural memories\n",
    "    for memory in procedural:\n",
    "        category = memory.get(\"category\", \"general\")\n",
    "        content = memory.get(\"content\", \"\")\n",
    "        context_parts.append(f\"- [Procedural: {category}] {content}\")\n",
    "    \n",
    "    return \"\\n\".join(context_parts) if context_parts else \"No user context available.\"\n",
    "\n",
    "# Initialize clients\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "gaugid_client = GaugidClient(connection_token=os.environ[\"GAUGID_CONNECTION_TOKEN\"])\n",
    "\n",
    "# Load user context (connection token mode - no DID needed)\n",
    "user_context = await load_user_context(gaugid_client)\n",
    "print(\"User context loaded:\")\n",
    "print(user_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create personalized agents with user context\n",
    "base_system_prompt = f\"\"\"You are part of a multi-agent system that helps users with various tasks.\n",
    "\n",
    "## USER PROFILE (from Gaugid)\n",
    "{user_context}\n",
    "\n",
    "## Guidelines\n",
    "- Adapt your communication style to match user preferences\n",
    "- Reference their expertise level when explaining concepts\n",
    "- Consider their current projects and learning goals\n",
    "- Be aware of their tool preferences\n",
    "- Personalize examples and recommendations\n",
    "\n",
    "Be helpful, technical, and precise. Adapt to the user's expertise level.\"\"\"\n",
    "\n",
    "# Research Agent\n",
    "research_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    system_instruction=f\"\"\"{base_system_prompt}\n",
    "\n",
    "You are a Research Specialist. Your role is to conduct thorough research on user topics.\n",
    "You understand the user's interests, expertise level, and preferences.\"\"\",\n",
    ")\n",
    "\n",
    "# Writing Agent\n",
    "writing_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    system_instruction=f\"\"\"{base_system_prompt}\n",
    "\n",
    "You are a Content Writer. Your role is to create personalized content based on research.\n",
    "You adapt your writing style to match the user's preferences and expertise level.\"\"\",\n",
    ")\n",
    "\n",
    "# Analysis Agent\n",
    "analysis_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    system_instruction=f\"\"\"{base_system_prompt}\n",
    "\n",
    "You are a Data Analyst. Your role is to analyze information and provide personalized insights.\n",
    "You consider the user's professional background and interests when providing analysis.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Multi-agent system ready with 3 specialized agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GaugidMemoryService with ADK\n",
    "\n",
    "For production use, you can use `GaugidMemoryService` as a `MemoryService` implementation\n",
    "that integrates with Google ADK's memory system. This allows agents to:\n",
    "- Store session information in Gaugid profiles\n",
    "- Search Gaugid memories for relevant context\n",
    "- Use PreloadMemoryTool to automatically load memories\n",
    "\n",
    "See `examples/frameworks/gaugid_memory_service.py` for the full implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the research agent\n",
    "user_input = \"What are the latest trends in AI agent development?\"\n",
    "\n",
    "print(f\"User: {user_input}\")\n",
    "print(f\"\\nResearch Agent processing...\")\n",
    "\n",
    "response = research_model.generate_content(user_input)\n",
    "print(f\"\\nResearch Agent: {response.text}\")\n",
    "\n",
    "# Optionally, save the interaction as a memory\n",
    "memory_result = await gaugid_client.propose_memory(\n",
    "    content=f\"User asked about AI agent development trends\",\n",
    "    category=\"a2p:professional\",\n",
    "    memory_type=\"episodic\",\n",
    "    confidence=0.9,\n",
    "    context=\"Interaction with Google ADK research agent\"\n",
    ")\n",
    "print(f\"\\nMemory saved: {memory_result.get('proposal_id')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
